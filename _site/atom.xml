<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
 
 <title></title>
 <link href="/atom.xml" rel="self"/>
 <link href=""/>
 <updated>2014-10-29T00:01:40+08:00</updated>
 <id></id>
 <author>
   <name></name>
   <email></email>
 </author>

 
 <entry>
   <title>kafka单机部署</title>
   <link href="/2014/10/18/how-to-step-kafka-on-centos.html"/>
   <updated>2014-10-18T00:00:00+08:00</updated>
   <id>h/2014/10/18/how-to-step-kafka-on-centos</id>
   <content type="html">&lt;h1&gt;kafka单机部署&lt;/h1&gt;

&lt;p&gt;kafka是一种高吞吐量的分布式发布订阅消息系统,kafka是linkedin用于日志处理的分布式消息队列，linkedin的日志数据容量大，但对可靠性要求不高，其日志数据主要包括用户行为（登录、浏览、点击、分享、喜欢）以及系统运行日志（CPU、内存、磁盘、网络、系统及进程状态）&lt;/p&gt;

&lt;p&gt;官网：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#39;http://kafka.apache.org/&#39;&gt;http://kafka.apache.org/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;h2&gt;环境配置&lt;/h2&gt;

&lt;p&gt;jdk zookeeper 配置可参照 前面文章配置。
&lt;a href=&#39;/2014/09/18/how-to-step-storm-on-centos.html&#39; &gt;单机部署storm&lt;/a&gt;&lt;/p&gt;

&lt;h2&gt;kafka 安装&lt;/h2&gt;

&lt;p&gt;wget http://apache.fayea.com/apache-mirror/kafka/0.8.1.1/kafka_2.9.2-0.8.1.1.tgz
tar -zxf kafka_2.9.2-0.8.1.1.tgz
cd kafka_2.9.2-0.8.1.1/config/&lt;/p&gt;

&lt;p&gt;修改配置文件&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;broker.id=0
port=9092
host.name=10.37.129.3
num.network.threads=2
num.io.threads=8
socket.send.buffer.bytes=1048576
socket.request.max.bytes=104857600
log.dirs=/tmp/kafka-logs
num.partitions=2
log.flush.interval.messages=10000
log.flush.interval.ms=1000
log.retention.hours=168
log.retention.bytes=1073741824
log.segment.bytes=536870912
log.retention.check.interval.ms=60000
log.cleaner.enable=false
zookeeper.connect=10.37.129.3:2181 
zookeeper.connection.timeout.ms=1000000&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;启动&lt;/p&gt;

&lt;p&gt;./kafka-server-start.sh /export/home/server/kafka_2.8.0-0.8.1.1/config/server.properties&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;[2014-10-28 23:57:56,694] INFO [Socket Server on Broker 0], Started (kafka.network.SocketServer)
[2014-10-28 23:57:56,766] INFO Will not load MX4J, mx4j-tools.jar is not in the classpath (kafka.utils.Mx4jLoader$)
[2014-10-28 23:57:56,788] INFO 0 successfully elected as leader (kafka.server.ZookeeperLeaderElector)
[2014-10-28 23:57:56,918] INFO New leader is 0 (kafka.server.ZookeeperLeaderElector$LeaderChangeListener)
[2014-10-28 23:57:56,920] INFO Registered broker 0 at path /brokers/ids/0 with address 10.37.129.3:9092. (kafka.utils.ZkUtils$)
[2014-10-28 23:57:56,935] INFO [Kafka Server 0], started (kafka.server.KafkaServer)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;kafka 常用命令&lt;/h2&gt;

&lt;p&gt;新建一个TOPIC&lt;/p&gt;

&lt;p&gt;./kafka-topics.sh --create --topic kafkatopic --replication-factor 1 --partitions 1 --zookeeper localhost:2181&lt;/p&gt;

&lt;p&gt;发送消息至KAFKA&lt;/p&gt;

&lt;p&gt;./kafka-console-producer.sh --broker-list localhost:9092 --sync --topic kafkatopic&lt;/p&gt;

&lt;p&gt;另开一个终端，显示消息的消费&lt;/p&gt;

&lt;p&gt;./kafka-console-consumer.sh --zookeeper localhost:2181 --topic kafkatopic --from-beginning&lt;/p&gt;

&lt;p&gt; 查看kafka topics list
 bin/kafka-topics.sh --list --zookeeper localhost:2181
删除
 bin/kafka-run-class.sh kafka.admin.DeleteTopicCommand -topic topic_001 --zookeeper localhost:2181&lt;/p&gt;

&lt;h1&gt;总结&lt;/h1&gt;

&lt;p&gt;网上到不符合自己流程。简单记录吧。&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>二维数组中的查找</title>
   <link href="/2014/10/13/java-array.html"/>
   <updated>2014-10-13T00:00:00+08:00</updated>
   <id>h/2014/10/13/java-array</id>
   <content type="html">&lt;h1&gt;二维数组中的查找&lt;/h1&gt;

&lt;p&gt;数组是有序数据的集合，数组中的每个元素具有相同的数组名和下标来唯一地确定数组中的元素。数组是最简单的数据结构，它占据了一块连续的内存并按照顺序存储。创建数组时我们首先指定容量大小，然后根据大小分配内存。因此空间效率不好，经常有空闲区域没有得到充分利用。由于数据中的内存时连续的。于是可以根据下标读写任何元素。因此他的效率很高。&lt;/p&gt;

&lt;h2&gt;题目：&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;在一个二维数组中。每一行都按照从左到右递增顺序排序。&lt;/li&gt;
&lt;li&gt;每一列都按照从上到下递增的顺序排序。请完成一个函数。输出这样的一 个二维数组和一个整数&lt;/li&gt;
&lt;li&gt;判断数组中是否含有该整数&lt;/li&gt;
&lt;/ul&gt;


&lt;h3&gt;解法一&lt;/h3&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;private static int[][] data = {
            {1, 2, 8, 9},
            {2, 4, 9, 12},
            {4, 7, 10, 13},
            {6, 8, 11, 15}};

    /**
     * 查找int 值是否在数组中存在
     *
     * @param data
     * @param find
     */
    private static boolean findByEach(int[][] data, int find) {

        if (data.length &amp;lt; 0) {
            System.out.print(&amp;quot;二维数组空。查找数字不存在&amp;quot;);
            return false;
        }

        int count = 0;

        for (int i = 0; i &amp;lt; data.length; i++) {
            count++;
            for (int j = 0; j &amp;lt; data[i].length; j++) {
                count++;
                if (data[i][j] == find) {
                    System.out.print(String.format(&amp;quot;find success count[%s]&amp;quot;, count));
                    return true;
                }
            }

        }

        System.out.print(String.format(&amp;quot;find end count[%s]&amp;quot;, count));

        return false;

    }


      public static void main(String[] args) {

        System.out.println(findByEach(data, 0));
        System.out.println(findByEach(data, 7));
    }&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;执行查找方法 发现存在的时候执行了。13次。没有查找到时查找了 20次。有没有更好到办法呢。数据时递增的？可以根据递增的特性优化。
｀ find end count[20]false
   find success count[13]true
｀&lt;/p&gt;

&lt;h3&gt;优化后&lt;/h3&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;private static int[][] data = {
            {1, 2, 8, 9},
            {2, 4, 9, 12},
            {4, 7, 10, 13},
            {6, 8, 11, 15}};

      private static boolean findByArea(int[][] data, int find) {

        if (data.length &amp;lt; 0) {
            System.out.print(&amp;quot;二维数组空。查找数字不存在&amp;quot;);
            return false;
        }

        int count = 0;

        for (int i = 0; i &amp;lt; data.length; i++) {
            count++;
            if (data[i][0] &amp;lt; find) {
                for (int j = 0; j &amp;lt; data[i].length; j++) {
                    count++;
                    if (data[i][j] &amp;lt;= find) {
                        if (data[i][j] == find) {
                            System.out.print(String.format(&amp;quot;find success [%s]&amp;quot;, count));
                            return true;

                        }
                    } else {
                        break;
                    }
                }
            } else {
                break;
            }

        }

        //由于递增 所以可以根据递增判断查找大小

        System.out.print(String.format(&amp;quot;find end count[%s]&amp;quot;, count));
        return false;
    }

    public static void main(String[] args) {

        System.out.println(findByArea(data, 0));
        System.out.println(findByArea(data, 7));
    }&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;查找相同的数据。可以找到时执行11次。找不到时执行1次。
 ｀
 find end count[1]false
 find success [11]true
｀&lt;/p&gt;

&lt;h2&gt;总结&lt;/h2&gt;

&lt;p&gt;  当遇到需要解决一个复杂问题时。一个很有效当办法就是从一个具体当问题入手。通过分析简单具体当例子。试图寻找普遍的规律。&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>设计模式－单例</title>
   <link href="/2014/10/12/design-pattern-signleton.html"/>
   <updated>2014-10-12T00:00:00+08:00</updated>
   <id>h/2014/10/12/design-pattern-signleton</id>
   <content type="html">&lt;h1&gt;设计模式－单例&lt;/h1&gt;

&lt;p&gt;Singleton（单例）模式设计模式。由于设计模式在面向对象程序设计中有这举足轻重单作用。一些公司面试过程中很多公司都喜欢问一些设计模式相关问题。Singleton 是唯一一个能够用短短几十行代码完成都设计模式。因此singleton的类型的是一个很常见的面试题。&lt;/p&gt;

&lt;h2&gt;题目：设计一个类 我们只能生成一个实例&lt;/h2&gt;

&lt;h3&gt;解法一&lt;/h3&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;public class SingletonOffer {

    private SingletonOffer() {

    }

    private static SingletonOffer _instance = null;

    public static SingletonOffer instance() {
        if (null == _instance) {
            _instance = new SingletonOffer();
        }
        return _instance;

    }

    public static void main(String[] args) {
        System.out.print(SingletonOffer.instance());
    }

}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;评点&lt;/h2&gt;

&lt;p&gt;   SingletonOffer 把构造函数设为私有变量禁止他人创建。 只能静态 instance() 方法 创建SingletonOffer 实例。只有&lt;em&gt;instance 为null时才会创建实例。但是在多线程下由于并非问题会出现实例多个&lt;/em&gt;instance.&lt;/p&gt;

&lt;h3&gt;优化后&lt;/h3&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;public static SingletonOffer instance() {
        synchronized (_instance) {
            if (null == _instance) {

                _instance = new SingletonOffer();
            }
        }
        return _instance;

    }&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;  由于同一个时间只能有一个线程得到同步锁。当一个线程持有锁时第二个线程等待。第二个线程持有时就判断_instance 已经被实例化。这样就多线程多问题。但是每一次都需要锁比较消耗性能。客户进一步优化代码&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;public static SingletonOffer instance() {

        if (null == _instance) {
            synchronized (_instance) {
                if (null == _instance) {

                    _instance = new SingletonOffer();
                }
            }
        }
        return _instance;

    }&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;em&gt;instace 为null时加锁。当&lt;/em&gt;instace已经创建出来后。就不需要加锁了。&lt;/p&gt;

&lt;h2&gt;静态构造函数&lt;/h2&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;static SingletonOfferLock _instance =new SingletonOfferLock();
    private SingletonOfferLock(){

    }

    public static SingletonOfferLock instance(){
        return _instance;
    }

    public static void main(String[] args) {
        System.out.print(SingletonOfferLock.instance());
    }&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;  使用静态变量初始化_instance代码非常简洁。静态变量会在程序程序初始化时创建一个实例。 但是这个实例是系统控制的。无论需要不需要第一次调用SingletonOfferLock都会被创建。实例创建过早会降低内存的使用效率。&lt;/p&gt;

&lt;h2&gt;优化&lt;/h2&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;public class SingletonOfferLock {


    private SingletonOfferLock(){

    }

    public static SingletonOfferLock instance(){
        return Nested.instance;
    }

    public static void main(String[] args) {
        System.out.print(SingletonOfferLock.instance());
    }

   static class Nested{
       private  Nested(){

       }

       static final SingletonOfferLock instance = new SingletonOfferLock();
   }

}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;由于Nested是私有变量 别人无法使用Nested类型。因此只有我们第一次试图通过属性创建 instance 时。对象才被实例化。&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>flume 单机部署</title>
   <link href="/2014/10/10/how-to-install-flume.html"/>
   <updated>2014-10-10T00:00:00+08:00</updated>
   <id>h/2014/10/10/how-to-install-flume</id>
   <content type="html">&lt;h1&gt;flume 单机部署&lt;/h1&gt;

&lt;p&gt;Flume是一个分布式、可靠、和高可用的海量日志聚合的系统，支持在系统中定制各类数据发送方，用于收集数据；同时，Flume提供对数据进行简单处理，并写到各种数据接受方（可定制）的能力。&lt;/p&gt;

&lt;p&gt;开发环境：
- jdk 1.6&lt;br/&gt;
- maven
- linux&lt;/p&gt;

&lt;h2&gt;下载 flume&lt;/h2&gt;

&lt;p&gt;地址 &lt;code&gt;　http://www.apache.org/dyn/closer.cgi/flume/1.5.0/apache-flume-1.5.0-bin.tar.gz&lt;/code&gt;&lt;/p&gt;

&lt;h2&gt;修改配置文件&lt;/h2&gt;

&lt;p&gt;  ｀ tar zxvf apache-flume-1.5.0-bin.tar.gz｀
    vi flume.conf
    配置如下&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;a1.sources = r1
a1.sinks = k1
a1.channels = c1
 
a1.sources.r1.type = avro
a1.sources.r1.channels = c1
a1.sources.r1.bind = 0.0.0.0
a1.sources.r1.port = 4141
 
a1.sinks.k1.type = logger
 
a1.channels.c1.type = memory
a1.channels.c1.capacity = 1000
a1.channels.c1.transactionCapacity = 100
 
a1.sources.r1.channels = c1
a1.sinks.k1.channel = c1&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;修改
cp flume-env.sh.template flume-env.sh
添加环境
java path&lt;/p&gt;

&lt;h2&gt;启动flume&lt;/h2&gt;

&lt;p&gt;bin/flume-ng agent -c conf -f conf/avro.conf -n a1 -Dflume.root.logger=INFO,console&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;bash-4.1# bin/flume-ng agent -c conf -f conf/flume.conf -n a1 -Dflume.root.logger=INFO,console
Info: Sourcing environment configuration script /export/home/server/apache-flume-1.5.0-bin/conf/flume-env.sh
+ exec /export/home/server/jdk1.6.0_25/bin/java -Xmx20m -Dflume.root.logger=INFO,console -cp &amp;#39;/export/home/server/apache-flume-1.5.0-bin/conf:/export/home/server/apache-flume-1.5.0-bin/lib/*&amp;#39; -Djava.library.path= org.apache.flume.node.Application -f conf/flume.conf -n a1
2014-10-11 22:25:24,246 (lifecycleSupervisor-1-0) [INFO - org.apache.flume.node.PollingPropertiesFileConfigurationProvider.start(PollingPropertiesFileConfigurationProvider.java:61)] Configuration provider starting
2014-10-11 22:25:24,249 (conf-file-poller-0) [INFO - org.apache.flume.node.PollingPropertiesFileConfigurationProvider$FileWatcherRunnable.run(PollingPropertiesFileConfigurationProvider.java:133)] Reloading configuration file:conf/flume.conf
2014-10-11 22:25:24,254 (conf-file-poller-0) [INFO - org.apache.flume.conf.FlumeConfiguration$AgentConfiguration.addProperty(FlumeConfiguration.java:930)] Added sinks: k1 Agent: a1
2014-10-11 22:25:24,254 (conf-file-poller-0) [INFO - org.apache.flume.conf.FlumeConfiguration$AgentConfiguration.addProperty(FlumeConfiguration.java:1016)] Processing:k1
2014-10-11 22:25:24,255 (conf-file-poller-0) [INFO - org.apache.flume.conf.FlumeConfiguration$AgentConfiguration.addProperty(FlumeConfiguration.java:1016)] Processing:k1
2014-10-11 22:25:24,263 (conf-file-poller-0) [INFO - org.apache.flume.conf.FlumeConfiguration.validateConfiguration(FlumeConfiguration.java:140)] Post-validation flume configuration contains configuration for agents: [a1]
2014-10-11 22:25:24,263 (conf-file-poller-0) [INFO - org.apache.flume.node.AbstractConfigurationProvider.loadChannels(AbstractConfigurationProvider.java:150)] Creating channels
2014-10-11 22:25:24,274 (conf-file-poller-0) [INFO - org.apache.flume.channel.DefaultChannelFactory.create(DefaultChannelFactory.java:40)] Creating instance of channel c1 type memory
2014-10-11 22:25:24,281 (conf-file-poller-0) [INFO - org.apache.flume.node.AbstractConfigurationProvider.loadChannels(AbstractConfigurationProvider.java:205)] Created channel c1
2014-10-11 22:25:24,282 (conf-file-poller-0) [INFO - org.apache.flume.source.DefaultSourceFactory.create(DefaultSourceFactory.java:39)] Creating instance of source r1, type avro
2014-10-11 22:25:24,305 (conf-file-poller-0) [INFO - org.apache.flume.sink.DefaultSinkFactory.create(DefaultSinkFactory.java:40)] Creating instance of sink: k1, type: logger
2014-10-11 22:25:24,309 (conf-file-poller-0) [INFO - org.apache.flume.node.AbstractConfigurationProvider.getConfiguration(AbstractConfigurationProvider.java:119)] Channel c1 connected to [r1, k1]
2014-10-11 22:25:24,315 (conf-file-poller-0) [INFO - org.apache.flume.node.Application.startAllComponents(Application.java:138)] Starting new configuration:{ sourceRunners:{r1=EventDrivenSourceRunner: { source:Avro source r1: { bindAddress: 127.0.0.1, port: 4141 } }} sinkRunners:{k1=SinkRunner: { policy:org.apache.flume.sink.DefaultSinkProcessor@6719dc16 counterGroup:{ name:null counters:{} } }} channels:{c1=org.apache.flume.channel.MemoryChannel{name: c1}} }
2014-10-11 22:25:24,322 (conf-file-poller-0) [INFO - org.apache.flume.node.Application.startAllComponents(Application.java:145)] Starting Channel c1
2014-10-11 22:25:24,323 (conf-file-poller-0) [INFO - org.apache.flume.node.Application.startAllComponents(Application.java:160)] Waiting for channel: c1 to start. Sleeping for 500 ms
2014-10-11 22:25:24,352 (lifecycleSupervisor-1-0) [INFO - org.apache.flume.instrumentation.MonitoredCounterGroup.register(MonitoredCounterGroup.java:119)] Monitored counter group for type: CHANNEL, name: c1: Successfully registered new MBean.
2014-10-11 22:25:24,354 (lifecycleSupervisor-1-0) [INFO - org.apache.flume.instrumentation.MonitoredCounterGroup.start(MonitoredCounterGroup.java:95)] Component type: CHANNEL, name: c1 started
2014-10-11 22:25:24,823 (conf-file-poller-0) [INFO - org.apache.flume.node.Application.startAllComponents(Application.java:173)] Starting Sink k1
2014-10-11 22:25:24,824 (conf-file-poller-0) [INFO - org.apache.flume.node.Application.startAllComponents(Application.java:184)] Starting Source r1
2014-10-11 22:25:24,827 (lifecycleSupervisor-1-0) [INFO - org.apache.flume.source.AvroSource.start(AvroSource.java:220)] Starting Avro source r1: { bindAddress: 127.0.0.1, port: 4141 }...
2014-10-11 22:25:25,131 (lifecycleSupervisor-1-0) [INFO - org.apache.flume.instrumentation.MonitoredCounterGroup.register(MonitoredCounterGroup.java:119)] Monitored counter group for type: SOURCE, name: r1: Successfully registered new MBean.
2014-10-11 22:25:25,131 (lifecycleSupervisor-1-0) [INFO - org.apache.flume.instrumentation.MonitoredCounterGroup.start(MonitoredCounterGroup.java:95)] Component type: SOURCE, name: r1 started
2014-10-11 22:25:25,132 (lifecycleSupervisor-1-0) [INFO - org.apache.flume.source.AvroSource.start(AvroSource.java:245)] Avro source r1 started.&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;创建文件&lt;/h2&gt;

&lt;p&gt;新建窗口 新建文件
echo &quot;hello world&quot; log.00&lt;/p&gt;

&lt;h2&gt;使用avro-client发送文件&lt;/h2&gt;

&lt;p&gt;｀bin/flume-ng avro-client -c conf -H 127.0.0.1 -p 4141 -F log.00｀&lt;/p&gt;

&lt;p&gt;查看第一个窗口&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;2014-10-11 22:31:02,355 (New I/O  worker #1) [INFO - org.apache.avro.ipc.NettyServer$NettyServerAvroHandler.handleUpstream(NettyServer.java:171)] [id: 0xd0366a23, /127.0.0.1:41593 =&amp;gt; /127.0.0.1:4141] BOUND: /127.0.0.1:4141
2014-10-11 22:31:02,356 (New I/O  worker #1) [INFO - org.apache.avro.ipc.NettyServer$NettyServerAvroHandler.handleUpstream(NettyServer.java:171)] [id: 0xd0366a23, /127.0.0.1:41593 =&amp;gt; /127.0.0.1:4141] CONNECTED: /127.0.0.1:41593
2014-10-11 22:31:02,750 (New I/O  worker #1) [INFO - org.apache.avro.ipc.NettyServer$NettyServerAvroHandler.handleUpstream(NettyServer.java:171)] [id: 0xd0366a23, /127.0.0.1:41593 :&amp;gt; /127.0.0.1:4141] DISCONNECTED
2014-10-11 22:31:02,750 (New I/O  worker #1) [INFO - org.apache.avro.ipc.NettyServer$NettyServerAvroHandler.handleUpstream(NettyServer.java:171)] [id: 0xd0366a23, /127.0.0.1:41593 :&amp;gt; /127.0.0.1:4141] UNBOUND
2014-10-11 22:31:02,750 (New I/O  worker #1) [INFO - org.apache.avro.ipc.NettyServer$NettyServerAvroHandler.handleUpstream(NettyServer.java:171)] [id: 0xd0366a23, /127.0.0.1:41593 :&amp;gt; /127.0.0.1:4141] CLOSED
2014-10-11 22:31:02,750 (New I/O  worker #1) [INFO - org.apache.avro.ipc.NettyServer$NettyServerAvroHandler.channelClosed(NettyServer.java:209)] Connection to /127.0.0.1:41593 disconnected.
2014-10-11 22:31:06,891 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.LoggerSink.process(LoggerSink.java:70)] Event: { headers:{} body: 68 65 6C 6C 6F 20 77 6F 72 6C 64                hello world }&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;


&lt;h1&gt;总结&lt;/h1&gt;

&lt;p&gt;收集成功&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>mongodb 安装</title>
   <link href="/2014/09/30/how-to-make-mongodb.html"/>
   <updated>2014-09-30T00:00:00+08:00</updated>
   <id>h/2014/09/30/how-to-make-mongodb</id>
   <content type="html">&lt;h1&gt;mongodb 安装&lt;/h1&gt;

&lt;p&gt;项目中日志量增大。准备把日志存储起来 想把日志存到hbase但是rowkey设计比较麻烦。而且日之后查询到纬度也比较多。今天尝试把日志先写到redis 然后用队列在同步到mongodb.&lt;/p&gt;

&lt;p&gt;机子上的基本环境：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;centos&lt;/li&gt;
&lt;li&gt;mongodb&lt;/li&gt;
&lt;/ul&gt;


&lt;h2&gt;下载&lt;/h2&gt;

&lt;p&gt;  下载mongodb-linux-x86_64-2.4.9.tgz&lt;/p&gt;

&lt;p&gt;  修改配置文件&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;tar zxvf mongodb-linux-x86_64-2.4.9.tgz
mv mongodb-linux-x86_64-2.4.9 mongodb
cd mongodb
mkdir db
mkdir logs
cd bin&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;配置mongodb&lt;/h2&gt;

&lt;p&gt;新建配置文件&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;vi mongodb.conf
添加配置文件
dbpath = /export/data/mongo/db            
logpath = /export/data/mongo/log
logappend = true                  
 
port = 27017                     
fork = true&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;mongodb&lt;/h2&gt;

&lt;p&gt;  ./mongod --config mongodb.conf&lt;br/&gt;
  bin/mongo
  进入shell命令后&lt;/p&gt;

&lt;p&gt;  `
use likunran //切换数据库不存在不存在创建
db.addUser(“root”,&quot;123456&quot;)&lt;/p&gt;

&lt;p&gt;db.auth(&quot;root&quot;,&quot;123456”)&lt;br/&gt;
 `&lt;/p&gt;

&lt;p&gt;重启 mongodb&lt;/p&gt;

&lt;p&gt;使用账号和密码登录mongodb
mongo likunran -uroot -p123456&lt;/p&gt;

&lt;p&gt;show dbs
use likunran //切换数据库不存在不存在创建
show collections
db.likunran.insert({&#39;name&#39;:&#39;likunran&#39;});
show collections
db.likunran.find()&lt;/p&gt;

&lt;h1&gt;总结&lt;/h1&gt;

&lt;p&gt;在本地模式运行成功&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>storm 结合 mybatis 数据 入库</title>
   <link href="/2014/09/27/how-to-mysql-on-storm.html"/>
   <updated>2014-09-27T00:00:00+08:00</updated>
   <id>h/2014/09/27/how-to-mysql-on-storm</id>
   <content type="html">&lt;h1&gt;storm 结合 mybatis 数据 入库&lt;/h1&gt;

&lt;p&gt;storm strom-starter-master  项目WordCountTopology 进行操作数据扩展。使用 druid作为数据源 用spring+mybatis 计算结果写到msql中。&lt;/p&gt;

&lt;p&gt;机子上的基本环境：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;mysql&lt;/li&gt;
&lt;li&gt;idea&lt;/li&gt;
&lt;/ul&gt;


&lt;h2&gt;mysql&lt;/h2&gt;

&lt;p&gt;  1.本地已经安装 mysql 启动mysql&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;bash-4.1#   /etc/init.d/mysqld  start
  正在启动 mysqld： [确定]&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt; 执行：&lt;code&gt;mysql -uroot -p123456&lt;/code&gt;，提示：&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;Copyright (c) 2000, 2013, Oracle and/or its affiliates. All rights reserved.

Oracle is a registered trademark of Oracle Corporation and/or its
affiliates. Other names may be trademarks of their respective
owners.

Type &amp;#39;help;&amp;#39; or &amp;#39;\h&amp;#39; for help. Type &amp;#39;\c&amp;#39; to clear the current input statement.

mysql&amp;gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;2.建立数据库和数据表 完成后结果如下&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;mysql&amp;gt; use uyicu
Reading table information for completion of table and column names
You can turn off this feature to get a quicker startup with -A

Database changed
mysql&amp;gt; desc system_log
    -&amp;gt; ;
+-------------+---------------+------+-----+---------+----------------+
| Field       | Type          | Null | Key | Default | Extra          |
+-------------+---------------+------+-----+---------+----------------+
| id          | int(4)        | NO   | PRI | NULL    | auto_increment |
| log_name    | varchar(1000) | YES  |     | NULL    |                |
| log_value   | varchar(1000) | YES  |     | NULL    |                |
| create_time | datetime      | YES  |     | NULL    |                |
| modify_time | datetime      | YES  |     | NULL    |                |
| yn          | int(11)       | YES  |     | NULL    |                |
+-------------+---------------+------+-----+---------+----------------+
6 rows in set (0.00 sec)

mysql&amp;gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;strom-starter 添加 pom依赖&lt;/h2&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;&amp;lt;dependency&amp;gt;
                &amp;lt;groupId&amp;gt;org.springframework&amp;lt;/groupId&amp;gt;
                &amp;lt;artifactId&amp;gt;spring-core&amp;lt;/artifactId&amp;gt;
                &amp;lt;version&amp;gt;${spring.version}&amp;lt;/version&amp;gt;
            &amp;lt;/dependency&amp;gt;
            &amp;lt;dependency&amp;gt;
                &amp;lt;groupId&amp;gt;org.springframework&amp;lt;/groupId&amp;gt;
                &amp;lt;artifactId&amp;gt;spring-beans&amp;lt;/artifactId&amp;gt;
                &amp;lt;version&amp;gt;${spring.version}&amp;lt;/version&amp;gt;
            &amp;lt;/dependency&amp;gt;
            &amp;lt;dependency&amp;gt;
                &amp;lt;groupId&amp;gt;org.springframework&amp;lt;/groupId&amp;gt;
                &amp;lt;artifactId&amp;gt;spring-context&amp;lt;/artifactId&amp;gt;
                &amp;lt;version&amp;gt;${spring.version}&amp;lt;/version&amp;gt;
            &amp;lt;/dependency&amp;gt;
            &amp;lt;dependency&amp;gt;
                &amp;lt;groupId&amp;gt;org.springframework&amp;lt;/groupId&amp;gt;
                &amp;lt;artifactId&amp;gt;spring-context-support&amp;lt;/artifactId&amp;gt;
                &amp;lt;version&amp;gt;${spring.version}&amp;lt;/version&amp;gt;
            &amp;lt;/dependency&amp;gt;

            &amp;lt;dependency&amp;gt;
                &amp;lt;groupId&amp;gt;org.springframework&amp;lt;/groupId&amp;gt;
                &amp;lt;artifactId&amp;gt;spring-aop&amp;lt;/artifactId&amp;gt;
                &amp;lt;version&amp;gt;${spring.version}&amp;lt;/version&amp;gt;
            &amp;lt;/dependency&amp;gt;
            &amp;lt;dependency&amp;gt;
                &amp;lt;groupId&amp;gt;org.springframework&amp;lt;/groupId&amp;gt;
                &amp;lt;artifactId&amp;gt;spring-aspects&amp;lt;/artifactId&amp;gt;
                &amp;lt;version&amp;gt;${spring.version}&amp;lt;/version&amp;gt;
            &amp;lt;/dependency&amp;gt;
            &amp;lt;dependency&amp;gt;
                &amp;lt;groupId&amp;gt;org.springframework&amp;lt;/groupId&amp;gt;
                &amp;lt;artifactId&amp;gt;spring-tx&amp;lt;/artifactId&amp;gt;
                &amp;lt;version&amp;gt;${spring.version}&amp;lt;/version&amp;gt;
            &amp;lt;/dependency&amp;gt;
            &amp;lt;dependency&amp;gt;
                &amp;lt;groupId&amp;gt;org.springframework&amp;lt;/groupId&amp;gt;
                &amp;lt;artifactId&amp;gt;spring-jdbc&amp;lt;/artifactId&amp;gt;
                &amp;lt;version&amp;gt;${spring.version}&amp;lt;/version&amp;gt;
            &amp;lt;/dependency&amp;gt;
              &amp;lt;dependency&amp;gt;
            &amp;lt;groupId&amp;gt;mysql&amp;lt;/groupId&amp;gt;
            &amp;lt;artifactId&amp;gt;mysql-connector-java&amp;lt;/artifactId&amp;gt;
            &amp;lt;version&amp;gt;5.1.26&amp;lt;/version&amp;gt;
        &amp;lt;/dependency&amp;gt;

        &amp;lt;dependency&amp;gt;
            &amp;lt;groupId&amp;gt;org.mybatis&amp;lt;/groupId&amp;gt;
            &amp;lt;artifactId&amp;gt;mybatis-spring&amp;lt;/artifactId&amp;gt;
            &amp;lt;version&amp;gt;1.2.0&amp;lt;/version&amp;gt;
        &amp;lt;/dependency&amp;gt;
        &amp;lt;dependency&amp;gt;
            &amp;lt;groupId&amp;gt;org.mybatis&amp;lt;/groupId&amp;gt;
            &amp;lt;artifactId&amp;gt;mybatis&amp;lt;/artifactId&amp;gt;
            &amp;lt;version&amp;gt;3.2.2&amp;lt;/version&amp;gt;
        &amp;lt;/dependency&amp;gt;
        &amp;lt;dependency&amp;gt;
            &amp;lt;groupId&amp;gt;com.alibaba&amp;lt;/groupId&amp;gt;
            &amp;lt;artifactId&amp;gt;druid&amp;lt;/artifactId&amp;gt;
            &amp;lt;version&amp;gt;0.2.25&amp;lt;/version&amp;gt;
        &amp;lt;/dependency&amp;gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;添加spring+mybatis配置文件&lt;/h2&gt;

&lt;p&gt;   mybatis 配置大家开参考 spring mybatis配置篇
   添加 spring-config.xml
       spring-config-dao.xml&lt;/p&gt;

&lt;h2&gt;添加SpringUtils&lt;/h2&gt;

&lt;p&gt;   springUtils用于加载spring 配置
  ｀&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;public static void build() {

    if (null == factory) {
        factory = new ClassPathXmlApplicationContext(&quot;spring-config.xml&quot;);
    }

}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;｀&lt;/p&gt;

&lt;h2&gt;storm RandomSentenceSpout 代码修改&lt;/h2&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;private ULogMapper uLogMapper;


    /**
     * open 方法用于初始化
     * @param conf
     * @param context
     * @param collector
     */
  @Override
  public void open(Map conf, TopologyContext context, SpoutOutputCollector collector) {
    _collector = collector;

      uLogMapper= SpringUtils.uLogMapperInstance();
      _rand = new Random();
  }

    /**
     * 在SpoutTracker类中被调用，每调用一次就可以向storm集群中发射一条数据（一个Tuple元组），该方法会被不停的调用
     */
  @Override
  public void nextTuple() {



      ULog uLog=new ULog();
      uLog.setCreateTime(new Date());
      uLog.setLogName(&amp;quot;nameSpout&amp;quot;);
      uLog.setLogValue(&amp;quot;value&amp;quot;);
      uLogMapper.insert(uLog) ;

    Utils.sleep(100);
    String[] sentences = new String[]{ &amp;quot;the cow jumped over the moon&amp;quot;, &amp;quot;an apple a day keeps the doctor away&amp;quot;,
        &amp;quot;four score and seven years ago&amp;quot;, &amp;quot;snow white and the seven dwarfs&amp;quot;, &amp;quot;i am at two with nature&amp;quot; };
    String sentence = sentences[_rand.nextInt(sentences.length)];
    _collector.emit(new Values(sentence));
  }&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;


&lt;h1&gt;总结&lt;/h1&gt;

&lt;p&gt;在本地模式运行成功&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>storm提交程序 strom-starter-master</title>
   <link href="/2014/09/23/how-to-deploy-strom-master.html"/>
   <updated>2014-09-23T00:00:00+08:00</updated>
   <id>h/2014/09/23/how-to-deploy-strom-master</id>
   <content type="html">&lt;h1&gt;storm提交程序 strom-starter-master&lt;/h1&gt;

&lt;p&gt;storm 已经部署完成准备写个例子测试下storm安装是否成功。当然选择了经典的代码storm-starter-master&lt;/p&gt;

&lt;p&gt;开发环境：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;idea&lt;/li&gt;
&lt;li&gt;jdk 1.6&lt;/li&gt;
&lt;li&gt;maven&lt;/li&gt;
&lt;li&gt;git&lt;/li&gt;
&lt;/ul&gt;


&lt;h2&gt;下载 strom-starter-master&lt;/h2&gt;

&lt;p&gt;运行 &lt;code&gt;git clone https://github.com/nathanmarz/storm-starter.git&lt;/code&gt;，提示：&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;localhost:log likunran$ git clone https://github.com/nathanmarz/storm-starter.gi
Cloning into &amp;#39;storm-starter.gi&amp;#39;...
remote: Repository not found.
fatal: repository &amp;#39;https://github.com/nathanmarz/storm-starter.gi/&amp;#39; not found
localhost:log likunran$ git clone https://github.com/nathanmarz/storm-starter.git
Cloning into &amp;#39;storm-starter&amp;#39;...
remote: Counting objects: 756, done.
remote: Total 756 (delta 0), reused 0 (delta 0)
Receiving objects: 100% (756/756), 171.81 KiB | 117.00 KiB/s, done.
Resolving deltas: 100% (274/274), done.
Checking connectivity... done.&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;maven 安装&lt;/h2&gt;

&lt;p&gt;运行 ｀maven&#39; 命令查看 maven是否安装&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;localhost:log likunran$ maven
-bash: maven: command not found&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;maven 没有安装，下载maven 配置环境变量&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;./etc/profile 文件   全局共有配置，无论哪个用户登录，都会读取此&gt; 文件
/etc/bashrc    （一般在这个文件中添加系统级环境变量）全局（公有）配置，bash shell执行时，不管是何种方式，都会读取此文件。
~/.bash_profile  （一般在这个文件中添加用户级环境变量）&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;添加环境变量&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;MAVEN_HOME=/Users/likunran/tools/apache-maven-2.2.1
PATH=$MAVEN_HOME/bin:$PATH
export MAVEN_HOME
export PATH&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt; &lt;code&gt;source .bash_profile&lt;/code&gt;&lt;/p&gt;

&lt;h2&gt;项目编译&lt;/h2&gt;

&lt;p&gt;   1.进入到storm-starter 文件夹 把 m2-pom.xml重命&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;mv m2-pom.xml pom.xml&lt;/br&gt;
mvn install&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;   编译结果&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;[INFO] BUILD SUCCESSFUL
[INFO] ------------------------------------------------------------------------
[INFO] Total time: 9 seconds
[INFO] Finished at: Tue Sep 23 23:36:05 CST 2014
[INFO] Final Memory: 40M/85M&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;编译过程中请保持外网是可以正常访问的&lt;/p&gt;

&lt;h2&gt;部署 到storm&lt;/h2&gt;

&lt;p&gt;1.进入 target目录看到storm-starter-0.0.1-SNAPSHOT-jar-with-dependencies.jar 文件已经存在。把文件部署到 storm&lt;/p&gt;

&lt;p&gt;2.提交 &lt;code&gt;./storm jar /export/data/storm/storm-starter-0.0.1-SNAPSHOT-jar-with-dependencies.jar storm.starter.WordCountTopology wordcountTop －100&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;3.访问storm ui&lt;/p&gt;

&lt;p&gt;http://10.37.129.3:8080/
图如下
&lt;img src=&quot;/css/images/st2.png&quot; alt=&quot;Alt text&quot; height=&quot;300&quot;&gt;&lt;/p&gt;

&lt;h1&gt;总结&lt;/h1&gt;

&lt;p&gt;有时候打包提交 会报错 Storm Found multiple defaults.yaml resources 。遇到这错误是因为storm的storm的defaultsyarm打进去了。这个文件在storm-core.jar里面已经有了，设置storm依赖的scope为provided好了&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Centos 下 storm 单机部署</title>
   <link href="/2014/09/18/how-to-step-storm-on-centos.html"/>
   <updated>2014-09-18T00:00:00+08:00</updated>
   <id>h/2014/09/18/how-to-step-storm-on-centos</id>
   <content type="html">&lt;h1&gt;Centos 下 storm 单机部署&lt;/h1&gt;

&lt;p&gt;从去年做广告效果统计接触storm开始。开始了解了storm 也有一段时间了。这段时间想在自己机器上部署个storm 但是发现网上没有太好点教程就决定自己写一篇单机部署。&lt;/p&gt;

&lt;p&gt;机子上的基本环境：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;parallels 虚拟机&lt;/li&gt;
&lt;li&gt;centos&lt;/li&gt;
&lt;li&gt;python 2.6&lt;/li&gt;
&lt;/ul&gt;


&lt;h2&gt;jdk 替换&lt;/h2&gt;

&lt;p&gt;  1.首先卸载centos自带openjdk.
  2.官网下载jdk .
  3.配置环境变量 &lt;code&gt;vi /etc/profile&lt;/code&gt;&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;You are missing a library required for Markdown. Please run:ls
export JAVA_HOME=/export/home/server/jdk1.6.0_25
export CLASSPATH=$JAVA_HOME/jre/lib:$JAVA_HOME/lib
export PATH=$PATH:$JAVA_HOME/bin&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;运行 java：&lt;code&gt;java -version&lt;/code&gt;，提示：&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;You are missing a library required for Markdown. Please run:
java version &amp;quot;1.6.0_65&amp;quot;
Java(TM) SE Runtime Environment (build 1.6.0_65-b14-462-11M4609)
Java HotSpot(TM) 64-Bit Server VM (build 20.65-b04-462, mixed mode)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;python 安装&lt;/h2&gt;

&lt;p&gt;运行 ｀python -v｀ 命令查看python 版本&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;# installing zipimport hook
import zipimport # builtin
# installed zipimport hook
# /usr/lib64/python2.6/site.pyc matches /usr/lib64/python2.6/site.py&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;python 2.6 版本已经存在无需安装&lt;/p&gt;

&lt;h2&gt;ZooKeeper 安装&lt;/h2&gt;

&lt;p&gt;   1.官网下载zookeeper&lt;/p&gt;

&lt;p&gt;   修改配置文件如下&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;tickTime=2000
dataDir=/home/hadoop/storage/zookeeper
clientPort=2181
initLimit=5
syncLimit=2&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;具体的配置项的解释大家可以自己去查&lt;/p&gt;

&lt;h2&gt;ZeroMQ 安装&lt;/h2&gt;

&lt;p&gt;从 http://download.zeromq.org/zeromq-2.1.7.tar.gz 下载&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;tar zxf zeromq-2.1.7.tar.gz
cd zeromq-2.1.7
./configure
make
make install
sudo ldconfig&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;jzmq 安装&lt;/h2&gt;

&lt;p&gt;从http://github.com/nathanmarz/jzmq页面下载jzmq-master.zip&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;unzip -zxvf jzmq-master.zip
cd jzmq
./autogen.sh
./configure
make
make install&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;Strom 安装&lt;/h2&gt;

&lt;p&gt; 我下载的是 0.9.0.1 这个版本可以选择是 jzmq或netty
 修改配置文件如下&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;storm.zookeeper.servers:
     - &amp;quot;localhost&amp;quot;

storm.zookeeper.port: 2181
storm.local.dir: /export/data/storm/tmp
nimbus.host: &amp;quot;localhost&amp;quot;
supervisor.slots.ports:
    - 6700
    - 6701
    - 6702
    - 6703&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;由于我现在是单机部署 所以配置loccalhost  zookeeper.port 配置 刚才　zk 端口 2181&lt;/p&gt;

&lt;p&gt;启动 strom&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;storm nimbus&amp;amp;
storm supervisor&amp;amp;
storm ui&amp;amp;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;查看日志
｀tail -f ui.log｀&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;2014-09-18 22:09:40 o.m.log [INFO] Logging to Logger[org.mortbay.log] via org.mortbay.log.Slf4jLog
2014-09-18 22:09:40 o.m.log [INFO] Started SocketConnector@0.0.0.0:8080&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;访问strom ui&lt;/p&gt;

&lt;p&gt;http://10.37.129.3:8080/
图如下
&lt;img src=&quot;/css/images/sui.png&quot; alt=&quot;Alt text&quot; height=&quot;300&quot;&gt;&lt;/p&gt;

&lt;h1&gt;总结&lt;/h1&gt;

&lt;p&gt;在安装过程中 zeromq 刚开始报错很多。根据提示一步步装其他软件就可以搞定。在外部访问虚拟机strom ui时 记得把端口打开&lt;/p&gt;
</content>
 </entry>
 
 
</feed>
